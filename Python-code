import pandas as pd
from nltk.corpus import stopwords
import re
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import KFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier
#loading and preprocessing####################################################################
import pandas as pd
data = open("C:/Users/karth/OneDrive/Desktop/Book1.txt").read()
rawdata = data.replace('\t', '\n').split('\n')
label= rawdata[0::2]
label = label[:-1]
df = pd.DataFrame({'label':label , 'body':text})
#removal of punctuation##########################################################################
def nonpunc(text):
    nonpunc_label ="".join([char for char in text if char not in string.punctuation])
return nonpunc_label 
df['nonpunc_label'] = df['label'].apply(lambda x: nonpunc(x))
#removal of stopwords############################################################################
stopwords = stopwords.words('english')
def nonpunc(text):
    nonpunc_label =[word for word in text if word not in stopwords])
    return nonpunc_label 
df['nonpunc'] = df['body'].apply(lambda x: nonpunc(x))

#creating the dataframe###########################################################################

main_df = df[['nonpunc' , 'nonpunc_label']]
#converting word to vector with countvectorizer using ngram=2 as function and displaying the feature names###########################
ngram_vect = CountVectorizer(ngram_range=(2,2))
xcounts = ngram_vect.fit_transform(main_df['nonpunc'])
print(xcounts.shape)
print(ngram_vect.get_feature_names())
tf_sparse = pd.DataFrame(xcounts)
tf_sparse.columns = ngram_vect.get_feature_names()

#creating a random forest classifier and initialising k-fold cross validation
rf = RandomForestClassifier(n_jobs=-1)
k_fold = KFold(n_splits=5)
cross_val_score(rf, x_features, main_df['nonpunc_label'], cv=k_fold, scoring='accuracy', n_jobs=-1)
x_train, x_test, y_train, y_test = train_test_split(x_features, main_df['nonpunc_label'], test_size=0.2)
#training the random forest classifier######################################################################
rf = RandomForestClassifier(n_estimators=50, max_depth=25, n_jobs=-1)
rf_model = rf.fit(x_train, y_train)
sorted(zip(rf_model.feature_importances_, x_train) , reverse=True)[0:10]

#prediction and testing####################################################################
y_pred = rf_model.predict(x_test)
print(precision_score(y_pred, y_test, average="macro"))
